# ğŸ“ Smart Call Assistant â€“ Intelligent Voice Response System  
**By Mohammad Askari **  
<img width="1917" height="977" alt="image" src="https://github.com/user-attachments/assets/571dbc91-47a0-4c92-a7ff-1f9d638075bb" />


## ğŸš€ Overview  
This project is a **complete intelligent voice assistant system** for phone call centers.  
It processes user speech, understands the intent, generates context-aware responses using a Large Language Model, and returns synthesized voice â€” all fully automated.

> ğŸ’¡ Built from scratch without external paid APIs, deployed & tested on real server under constraints.

## ğŸ¯ Core Features

- ğŸ™ï¸ **Speech-to-Text (STT)** using **OpenAI Whisper**
- ğŸ§  **Intent Detection & Sentiment Analysis** (Keyword-based + optional Transformers)
- ğŸ¤– **LLM-based Response Generation** (GPT-compatible endpoint)
- ğŸ”Š **Text-to-Speech (TTS)** using **Google Gemini (genai)**
- ğŸ–¥ï¸ **Flask-based Web Dashboard** to upload and interact with the system
- ğŸ“Š **SQLite Logging** of all calls, processing metrics & quality indicators
- ğŸ§ª **End-to-End and Concurrent Load Testing** tools
- âš™ï¸ Modular pipeline: audio enhancement â†’ STT â†’ NLP â†’ GPT â†’ TTS â†’ audio playback

## ğŸ“ Project Structure
```
app/
â”œâ”€â”€ audio/              # Audio pre-processing & noise reduction
â”œâ”€â”€ stt/                # Speech-to-text (Whisper)
â”œâ”€â”€ gpt/                # GPT client abstraction (Metis endpoint)
â”œâ”€â”€ tts/                # TTS using Google Gemini
â”œâ”€â”€ analysis/           # Intent and sentiment analysis
â”œâ”€â”€ database/           # SQLite interface and schema
â”œâ”€â”€ templates/          # Flask front-end
â”œâ”€â”€ main.py             # Full pipeline logic
â”œâ”€â”€ app.py              # Flask API and UI
config/
â”œâ”€â”€ .env                # Environment variables
tests/
â”œâ”€â”€ test_system.py      # E2E tests
â”œâ”€â”€ concurrency_test.py # Load testing with concurrency
```

## ğŸ”§ How It Works

1. **User speaks** during a phone call.
2. **Audio is processed** and passed to Whisper â†’ converts speech to text.
3. **Intent & sentiment** extracted from transcript.
4. **LLM (GPT)** generates a context-aware answer using predefined knowledge.
5. **TTS** converts the answer to voice (using Gemini API).
6. **Audio response is played back** to the caller.
7. **Call logs** (duration, quality, timings) are saved to SQLite for monitoring.

## ğŸ“· Demo Screenshot  
_(Add here a screenshot of the Flask UI showing audio upload and response)_  
â†’ `static/screenshots/demo.png`

## âš™ï¸ Tech Stack  
- Python 3.11  
- Flask  
- OpenAI Whisper  
- Google genai (TTS)  
- SQLite  
- Transformers (optional for NLP)  
- Gunicorn (production WSGI)  

## ğŸ“Œ Requirements  
- `pip install -r requirements.txt`  
- Add `.env` file with keys for GPT and Gemini APIs.

## ğŸš€ Run Instructions

```bash
# Install dependencies
pip install -r requirements.txt

# Run Flask app
python app/app.py

# Or with Gunicorn (recommended)
gunicorn app.app:app -w 2 -b 0.0.0.0:5000
```

## ğŸ“Š Metrics Tracked
- `processing_time` â€“ full pipeline latency
- `gpt_quality` â€“ subjective quality score
- `intent`, `sentiment`, `response_text`
- File paths for input/output audio

<img width="1821" height="581" alt="image" src="https://github.com/user-attachments/assets/203a6b71-a5e1-4c65-b92a-7050ed98d229" />

## ğŸ’¡ Highlights
- Designed & implemented fully **solo**.
- Delivered under **tight technical limitations** (no paid APIs or DevOps).
- Production-oriented code with modularity, testing, and database integration.
- Real-time & batch audio processing tools included.

## ğŸ“ About the Developer  
ğŸ‘¨â€ğŸ“ **Mohammad Askari**  
Final-year Electrical Engineering student @ **University of Tehran**
Interested in **Quantitative Finance, Optimization, AI, and Markets**  

